# 2.0 Prerequisites & Setup

Required versions of products used:

| Product         | Versions    |
| -----------     | ----------- |
| OpenShift 3.x   | v3.7+       |
| OpenShift 4.x   | v4.1+       |

Additionally, temporary object storage will be required perform a migration.  This can be provided through: [AWS S3](https://aws.amazon.com/s3/), [Noobaa](https://www.noobaa.io/), or [Minio](https://min.io/).

## 2.1 Base requirements

* A computer with access to the Internet :-)
* SSH client (for Microsoft Windows users [Putty](https://www.putty.org/) is recommended)
* Firefox 17 or higher, or Chromium / Chrome
* oc client [Download from try.openshift.com](http://try.openshift.com)

## 2.2 Accessing the Bastion Host & Client VM

For certain tasks in the lab, you will need to ssh into bastion host.  Remember that login details are presented by GuidGrabber.

e.g:

![SSH Details GuidGrabber](screenshots/ssh-details-gg.png)

For *sshing* in the bastion host you can use your favorite ssh-client.

~~~sh
ssh lab-user@bastion.GUID.DOMAIN

e.g: ssh lab-user@bastion.d5fe.events.opentlc.com
~~~


<a id="markdown-verifications" name="verifications"></a>
## 2.3 Verifications

### 2.3.1 Verify 3.11 environment

1. Log into the 3.11 environment
```bash
$ oc login https://master1.GUID.DOMAIN -u admin -p r3dh4t1!
The server uses a certificate signed by an unknown authority.
You can bypass the certificate check, but any data you send to the server could be intercepted by others.
Use insecure connections? (y/n): y
```
2. Verify that the `migration-operator` deployment is running in `mig` namespace and healthy
```bash
$ oc get deployment migration-operator -n mig
NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
migration-operator   1         1         1            1           5m
```

3. Verify that `velero` is now running on the source in the `mig` namespace
```
$ oc get pods -n mig | grep velero
velero-7559946c5c-mh5sp               1/1     Running   0          2m
```

### 2.3.2 Verify 4.1 environment

1. Log into the 4.1 environment
```bash
$ oc login https://api.cluster-GUID.GUID.DOMAIN:6443 -u admin -p r3dh4t1!
The server uses a certificate signed by an unknown authority.
You can bypass the certificate check, but any data you send to the server could be intercepted by others.
Use insecure connections? (y/n): y
```

1. Verify that you see the below pods now running in `mig` namespace, we are looking for pods of `controller-manager`, `velero`, and `migration-ui`
```bash
$ oc get pods -n mig
NAME                                 READY   STATUS      RESTARTS   AGE
migration-operator-437w4jd-88sf      1/1     Running     0          2m
controller-manager-79bf7cd7d-99sbr   1/1     Running     0          2m
migration-ui-6d84bb9879-w52qx        1/1     Running     0          2m
restic-6lhnp                         1/1     Running     0          2m
velero-6bf58f4f88-6cpw8              1/1     Running     0          2m
```

## 2.4 CORS Configuration

CAM's UI is served out of the cluster
behind its own route, there are 3 distinct origins at play:

* The UI - (Ex: https://mig-ui-mig.apps.examplecluster.com)
* The OAuth Server - (Ex: https://openshift-authentication-openshift-authentication.apps.examplecluster.com)
* The API Server - (Ex: https://api.examplecluster.com:6443)

When the UI is served to the browser through it's route, the browser recognizes
its origin, and **blocks AJAX requests to alternative origins**. This is called
[Cross-Origin Resource Sharing (CORS)](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS),
and it's a deliberate browser security measure.

The full description of CORS is linked above, but without configuring the non-UI
origin servers, the requests will be blocked. To enable these requests,
the UI's origin should be whitelisted in a `corsAllowedOrigins` list for each
alternative origin. The servers should recognize this list and inspect the
origin of incoming requests. If the origin matches one of the CORS whitelisted
origins (the UI), there are a set of headers that are returned in the response
that inform the browser the CORS request is accepted and valid.

Additionally, for the same reasons described above, any requests that the UI
may make to source 3.x clusters will also have to be whitelisted by configuring
the same field in the 3.x cluster master-config.yaml. This causes the 3.x API
servers to accept the CORS requests incoming from the UI that was served out
of its OCP4 cluster's route.

1. SSH into bastion Host (3.11 environment).
```bash
$ ssh lab-user@bastion.GUID.DOMAIN
```
2. Run the following playbook to enable the proper CORS headers on the source v3.11 cluster.  Be sure to provide the GUIDs for the 3.11 and 4.1 environments.  The cors.yaml is in the lab-user's home directory (/home/lab-user).
```
$ GUID_4=<guid_of_ocp4> DOMAIN=<domain_of_ocp4> ansible-playbook cors.yaml
```

e.g:
~~~
$ GUID_4=7f25 DOMAIN=sandbox605.opentlc.com ansible-playbook cors.yaml
[WARNING]: log file at /root/ansible.log is not writeable and we cannot create it, aborting


PLAY [localhost] *****************************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ***********************************************************************************************************************************************************************************************************************
ok: [localhost]

TASK [Fixing permissions of the key file] ****************************************************************************************************************************************************************************************************
changed: [localhost]

PLAY [masters] *******************************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ***********************************************************************************************************************************************************************************************************************
The authenticity of host 'master1.55b9.internal (192.168.0.127)' can't be established.
ECDSA key fingerprint is SHA256:M6vdO7YwQzFKmEybTwuqYLuLYPq3tTbpgNP7T6T6Yok.
ECDSA key fingerprint is MD5:9d:73:92:c2:92:41:8f:c6:9b:77:35:d6:97:5e:d8:29.
Are you sure you want to continue connecting (yes/no)? yes
ok: [master1.55b9.internal]

TASK [Adding new CORS rules] *****************************************************************************************************************************************************************************************************************
changed: [master1.55b9.internal]

TASK [Checking if atomic-openshift services exist] *******************************************************************************************************************************************************************************************
fatal: [master1.55b9.internal]: FAILED! => {"changed": true, "cmd": "systemctl status atomic-openshift-master-api", "delta": "0:00:00.006799", "end": "2019-08-19 14:09:36.933939", "msg": "non-zero return code", "rc": 4, "start": "2019-08-19 14:09:36.927140", "stderr": "Unit atomic-openshift-master-api.service could not be found.", "stderr_lines": ["Unit atomic-openshift-master-api.service could not be found."], "stdout": "", "stdout_lines": []}
...ignoring

TASK [Applying new configuration [atomic-openshift services]] ********************************************************************************************************************************************************************************
skipping: [master1.55b9.internal] => (item=atomic-openshift-master-api)
skipping: [master1.55b9.internal] => (item=atomic-openshift-master-controllers)

TASK [Applying new configuration [master-restart]] *******************************************************************************************************************************************************************************************
changed: [master1.55b9.internal] => (item=api)
changed: [master1.55b9.internal] => (item=controller)

PLAY RECAP ***********************************************************************************************************************************************************************************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0   
master1.55b9.internal      : ok=4    changed=3    unreachable=0    failed=0   
~~~



## 2.5 Prepare to use mig-ui from OCP 4.1 Cluster in your Browser
1. To visit the ui, look at the route on the OCP 4.1 Cluster
```bash
$ oc get routes migration -n mig -o jsonpath='{.spec.host}'
migration-mig.apps.cluster-0de0.0de0.sandbox335.opentlc.com
```

1. For this example we'd visit the below from our browser:
  * https://migration-mig.apps.cluster-a21d.a21d.sandbox67.opentlc.com

### 2.5.1 Accept Certificates on Source and Destination Clusters

1. Before you can login you will need to accept the certificates with your
   browser on both the source and destination cluster. To do this:
  * Visit the link displayed by the webui for `.well-known/oauth-authorization-server`.
    * For example:
      * OCP 4.1: https://api.cluster-0de0.0de0.sandbox335.opentlc.com:6443/.well-known/oauth-authorization-server
      * OCP 3.11 https://master.b79f.events.opentlc.com/.well-known/oauth-authorization-server
  * Refresh the page
  * Get redirected to login page
1. Login with your credentials for the cluster.
  * Username: admin
  * Password: `r3dh4t1!`
1. We also need to accept the certificates from the OCP 3.11 cluster
  * Visit the webui for OCP 3.11 console, for example: https://master.b79f.events.opentlc.com
  * Login with the credentials for the cluster.
    * Username: admin
    * Password: `r3dh4t1!`

## 2.6 Object Storage Setup

CAM leverages object storage as temporary scratch space when performing migrations.  This storage can be any object storage that presents an `S3 like` interface.  Currently, we have tested AWS S3, Noobaa, and Minio.  

For purposes of this lab, we have already deployed minio on the 4.2 cluster.  Let's proceed with creating a bucket for our use:

1. Let's get the route to the Minio web UI.
```
$ oc get route -n gpte-minio
NAME    HOST/PORT                                                        PATH   SERVICES   PORT   TERMINATION   WILDCARD
minio   minio-gpte-minio.apps.cluster-0de0.0de0.sandbox335.opentlc.com          minio      9000                 None
```

![Minio Login Screen](screenshots/minio_login.png)

2. Visit the route and login to manually create a bucket; login with Access Key: `minio` and Secret Key: `minio123`.  Any bucket name will suffice, we choose `mybucket`.

![Minio Bucket Creation](screenshots/minio-bucket-creation.png)

![Minio mybucket](screenshots/minio-mybucket.png)

We now have a bucket created.  We will use this during our migration exercises.


Next Lab: [Lab 3 - CPMA Overview](./3.md)<br>
[Home](../README.md)
